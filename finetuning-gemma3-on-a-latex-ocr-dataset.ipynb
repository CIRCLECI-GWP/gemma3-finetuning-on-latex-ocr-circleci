{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load requisite packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that GPU is enabled\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-12T06:04:30.189956Z",
     "iopub.status.busy": "2025-07-12T06:04:30.189730Z",
     "iopub.status.idle": "2025-07-12T06:04:56.735156Z",
     "shell.execute_reply": "2025-07-12T06:04:56.733995Z",
     "shell.execute_reply.started": "2025-07-12T06:04:30.189933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "\n",
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
    "!pip install transformers==4.52.4\n",
    "#!pip install transformers==4.53.1\n",
    "!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login to Hugging Face and WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:05:17.385687Z",
     "iopub.status.busy": "2025-07-12T06:05:17.384957Z",
     "iopub.status.idle": "2025-07-12T06:05:18.081272Z",
     "shell.execute_reply": "2025-07-12T06:05:18.080460Z",
     "shell.execute_reply.started": "2025-07-12T06:05:17.385651Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into Hugging Face.\n"
     ]
    }
   ],
   "source": [
    "# --- Hugging Face Login (for pushing the model) ---\n",
    "\n",
    "from huggingface_hub import login\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "    print(\"Logged into Hugging Face.\")\n",
    "else:\n",
    "    print(\"Warning: HF_TOKEN environment variable not set. Model pushing to Hugging Face might fail.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login to WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T19:21:30.672921Z",
     "iopub.status.busy": "2025-07-11T19:21:30.672385Z",
     "iopub.status.idle": "2025-07-11T19:21:45.421540Z",
     "shell.execute_reply": "2025-07-11T19:21:45.421007Z",
     "shell.execute_reply.started": "2025-07-11T19:21:30.672899Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzattubiz\u001b[0m (\u001b[33mzattuonline\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250711_192139-8oglq8p2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset/runs/8oglq8p2?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">scarlet-blaze-13</a></strong> to <a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset/runs/8oglq8p2?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset/runs/8oglq8p2?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wb_token = user_secrets.get_secret(\"wb_token\")\n",
    "\n",
    "wandb.login(key=wb_token)\n",
    "run = wandb.init(\n",
    "    project='Fine-tuning Gemma-3-4B on Latex-OCR Dataset', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect the dataset\n",
    "\n",
    "### About the data\n",
    "\n",
    "The study uses a sampled dataset of handwritten math formulas. The objective is to convert these images into a LaTeX (a computer-readable format) for rendering. This is important for creating math-solving apps that enable students to photograph math problems for LLMs to solve. \n",
    "\n",
    "You can access the sampled dataset [here](https://huggingface.co/datasets/unsloth/LaTeX_OCR) and the full dataset [here](https://huggingface.co/datasets/linxy/LaTeX_OCR).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset (for both train and test splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:07:43.704357Z",
     "iopub.status.busy": "2025-07-12T06:07:43.703626Z",
     "iopub.status.idle": "2025-07-12T06:07:54.376234Z",
     "shell.execute_reply": "2025-07-12T06:07:54.375650Z",
     "shell.execute_reply.started": "2025-07-12T06:07:43.704330Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading LaTeX_OCR dataset ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e20ba5ce45f497a87abed5a95d8db52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/519 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df9a468192544049e81a57a1cc90a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/344M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903b95d163624b05b22f41b39e56119c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/38.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dac997414c4a7899370f67162767ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/68686 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a1180ff8c346aead60d48a7ff8d00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7632 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset \n",
    "print(\"--- Loading LaTeX_OCR dataset ---\")\n",
    "train_dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"train\")\n",
    "test_dataset = load_dataset(\"unsloth/LaTeX_OCR\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T19:56:57.298968Z",
     "iopub.status.busy": "2025-07-11T19:56:57.298461Z",
     "iopub.status.idle": "2025-07-11T19:56:57.304728Z",
     "shell.execute_reply": "2025-07-11T19:56:57.304207Z",
     "shell.execute_reply.started": "2025-07-11T19:56:57.298942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 68686\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T19:57:11.346090Z",
     "iopub.status.busy": "2025-07-11T19:57:11.345484Z",
     "iopub.status.idle": "2025-07-11T19:57:11.351713Z",
     "shell.execute_reply": "2025-07-11T19:57:11.351035Z",
     "shell.execute_reply.started": "2025-07-11T19:57:11.346069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'text'],\n",
       "    num_rows: 7632\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T19:59:59.429989Z",
     "iopub.status.busy": "2025-07-11T19:59:59.429418Z",
     "iopub.status.idle": "2025-07-11T19:59:59.475949Z",
     "shell.execute_reply": "2025-07-11T19:59:59.475471Z",
     "shell.execute_reply.started": "2025-07-11T19:59:59.429958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[12][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a corresponding LateX code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:00:31.433025Z",
     "iopub.status.busy": "2025-07-11T20:00:31.432770Z",
     "iopub.status.idle": "2025-07-11T20:00:31.439689Z",
     "shell.execute_reply": "2025-07-11T20:00:31.438924Z",
     "shell.execute_reply.started": "2025-07-11T20:00:31.433007Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\frac { d \\\\varphi _ { s p h } } { d r } ( r \\\\rightarrow \\\\infty ) \\\\rightarrow 0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[12][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the equation for the LateX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:02:45.461457Z",
     "iopub.status.busy": "2025-07-11T20:02:45.460665Z",
     "iopub.status.idle": "2025-07-11T20:02:45.467890Z",
     "shell.execute_reply": "2025-07-11T20:02:45.467225Z",
     "shell.execute_reply.started": "2025-07-11T20:02:45.461431Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac { d \\varphi _ { s p h } } { d r } ( r \\rightarrow \\infty ) \\rightarrow 0$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "latex = train_dataset[12][\"text\"]\n",
    "display(Math(latex))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data before finetuning\n",
    "\n",
    "### Convert training data into conversation format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:03:56.210715Z",
     "iopub.status.busy": "2025-07-11T20:03:56.210429Z",
     "iopub.status.idle": "2025-07-11T20:04:19.147690Z",
     "shell.execute_reply": "2025-07-11T20:04:19.147132Z",
     "shell.execute_reply.started": "2025-07-11T20:03:56.210696Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Prepare the training data in conversation format\n",
    "instruction = \"Write the LaTeX representation for this image.\"\n",
    "def convert_to_conversation(sample):\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": instruction},\n",
    "                {\"type\": \"image\", \"image\": sample[\"image\"]},\n",
    "            ],\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": sample[\"text\"]}]},\n",
    "    ]\n",
    "    return {\"messages\": conversation}\n",
    "\n",
    "converted_train_dataset = [convert_to_conversation(sample) for sample in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:06:10.058159Z",
     "iopub.status.busy": "2025-07-11T20:06:10.057854Z",
     "iopub.status.idle": "2025-07-11T20:06:10.064957Z",
     "shell.execute_reply": "2025-07-11T20:06:10.064204Z",
     "shell.execute_reply.started": "2025-07-11T20:06:10.058137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'user',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': 'Write the LaTeX representation for this image.'},\n",
       "    {'type': 'image',\n",
       "     'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=160x40>}]},\n",
       "  {'role': 'assistant',\n",
       "   'content': [{'type': 'text',\n",
       "     'text': '\\\\frac { d \\\\varphi _ { s p h } } { d r } ( r \\\\rightarrow \\\\infty ) \\\\rightarrow 0'}]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_train_dataset[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the base model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T06:05:29.862833Z",
     "iopub.status.busy": "2025-07-12T06:05:29.862518Z",
     "iopub.status.idle": "2025-07-12T06:06:07.648805Z",
     "shell.execute_reply": "2025-07-12T06:06:07.648155Z",
     "shell.execute_reply.started": "2025-07-12T06:05:29.862809Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 06:05:43.439391: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752300343.650881      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752300343.714084      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "import torch\n",
    "from unsloth import FastVisionModel, get_chat_template # Import necessary unsloth components\n",
    "from datasets import load_dataset # Import load_dataset to get the dataset\n",
    "from trl import SFTTrainer, SFTConfig # Import for fine-tuning\n",
    "import difflib # Import difflib for sequence comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:16:39.008115Z",
     "iopub.status.busy": "2025-07-11T20:16:39.007550Z",
     "iopub.status.idle": "2025-07-11T20:16:56.243705Z",
     "shell.execute_reply": "2025-07-11T20:16:56.243120Z",
     "shell.execute_reply.started": "2025-07-11T20:16:39.008090Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading base Gemma-3-4B model and processor ---\n",
      "==((====))==  Unsloth 2025.7.3: Fast Gemma3 patching. Transformers: 4.52.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
     ]
    }
   ],
   "source": [
    "# This is the initial, pre-trained Gemma-3-4B model.\n",
    "print(\"--- Loading base Gemma-3-4B model and processor ---\")\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/gemma-3-4b-pt\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply chat template to the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:17:17.388301Z",
     "iopub.status.busy": "2025-07-11T20:17:17.387995Z",
     "iopub.status.idle": "2025-07-11T20:17:17.393911Z",
     "shell.execute_reply": "2025-07-11T20:17:17.393368Z",
     "shell.execute_reply.started": "2025-07-11T20:17:17.388279Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply chat template to the processor for conversational formatting\n",
    "processor = get_chat_template(\n",
    "    processor,\n",
    "    \"gemma-3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper function to Generate LateX from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:08:36.744720Z",
     "iopub.status.busy": "2025-07-11T20:08:36.744065Z",
     "iopub.status.idle": "2025-07-11T20:08:36.751462Z",
     "shell.execute_reply": "2025-07-11T20:08:36.750814Z",
     "shell.execute_reply.started": "2025-07-11T20:08:36.744687Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Helper Function: Generate LaTeX from an image ---\n",
    "def generate_latex_from_image(model_to_use, processor_to_use, image, instruction):\n",
    "    \"\"\"\n",
    "    Generates LaTeX representation for a given image using the provided model and processor.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": instruction}],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    input_text = processor_to_use.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = processor_to_use(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    output_ids = model_to_use.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        temperature=1.0,\n",
    "        top_p=0.95,\n",
    "        top_k=64\n",
    "    )\n",
    "\n",
    "    generated_text_ids = output_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    generated_latex = processor_to_use.decode(generated_text_ids, skip_special_tokens=True)\n",
    "    return generated_latex.replace(\"<end_of_turn>\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a helper function to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:14:15.991043Z",
     "iopub.status.busy": "2025-07-11T20:14:15.990758Z",
     "iopub.status.idle": "2025-07-11T20:14:15.995703Z",
     "shell.execute_reply": "2025-07-11T20:14:15.995129Z",
     "shell.execute_reply.started": "2025-07-11T20:14:15.991024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_latex_similarity(latex1, latex2):\n",
    "    \"\"\"\n",
    "    Calculates a similarity ratio between two LaTeX strings using SequenceMatcher.\n",
    "    Returns a float between 0.0 and 1.0.\n",
    "    \"\"\"\n",
    "    return difflib.SequenceMatcher(None, latex1, latex2).ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model before fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:14:28.617155Z",
     "iopub.status.busy": "2025-07-11T20:14:28.616486Z",
     "iopub.status.idle": "2025-07-11T20:14:45.990601Z",
     "shell.execute_reply": "2025-07-11T20:14:45.989975Z",
     "shell.execute_reply.started": "2025-07-11T20:14:28.617130Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing Model Performance BEFORE Fine-tuning\n",
      "==================================================\n",
      "\n",
      "--- Test Example (Index 12) BEFORE Fine-tuning ---\n",
      "Original LaTeX:\n",
      "{ \\partial } ^ { \\mu } A _ { \\mu } ^ { a b } = A ^ { \\mu a c } B _ { \\mu } ^ { c b } - B ^ { \\mu a c } A _ { \\mu } ^ { c b } ,\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle { \\partial } ^ { \\mu } A _ { \\mu } ^ { a b } = A ^ { \\mu a c } B _ { \\mu } ^ { c b } - B ^ { \\mu a c } A _ { \\mu } ^ { c b } ,$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LaTeX (Before Fine-tuning):\n",
      "CDCl_(4) is a type of solvent.CDCl_4 (or CDCl_3 DCl_3 or CCl_3 Cl_3) is an organic solvent, also used as a solvent for NMR spectroscopy for various reasons.CDCl_4 is the abbreviation of deuterated chloroform.CDCl_4 is a tetramethylsilane substituted, non-protonated CCl_3 CI_3.CDCl_4 is also an organic compound, non-protonated tetrafluorotolene, a colorless, volatile, extremely flammable liquid that can be used as a solvent for a fluorocarbon. It is the main ingredient in\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle CDCl_(4) is a type of solvent.CDCl_4 (or CDCl_3 DCl_3 or CCl_3 Cl_3) is an organic solvent, also used as a solvent for NMR spectroscopy for various reasons.CDCl_4 is the abbreviation of deuterated chloroform.CDCl_4 is a tetramethylsilane substituted, non-protonated CCl_3 CI_3.CDCl_4 is also an organic compound, non-protonated tetrafluorotolene, a colorless, volatile, extremely flammable liquid that can be used as a solvent for a fluorocarbon. It is the main ingredient in$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score (Before Fine-tuning): 0.0033\n",
      "Exact Match: NO (Expected before fine-tuning)\n",
      "\n",
      "Original Image:\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Test the model before fine-tuning\n",
    "\n",
    "# --- 3. Test the model BEFORE Fine-tuning ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Testing Model Performance BEFORE Fine-tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Set the base model to inference mode\n",
    "\n",
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "\n",
    "# Choose a specific example from the test set to evaluate initial performance\n",
    "test_example_index = 12 # You can change this index to test different examples\n",
    "image_test_case = test_dataset[test_example_index][\"image\"]\n",
    "original_latex_test_case = test_dataset[test_example_index][\"text\"]\n",
    "\n",
    "\n",
    "print(f\"\\n--- Test Example (Index {test_example_index}) BEFORE Fine-tuning ---\")\n",
    "\n",
    "generated_latex_before_finetune = generate_latex_from_image(model, processor, image_test_case, instruction)\n",
    "\n",
    "print(\"Original LaTeX:\")\n",
    "print(original_latex_test_case)\n",
    "display(Math(original_latex_test_case))\n",
    "\n",
    "print(\"Generated LaTeX (Before Fine-tuning):\")\n",
    "print(generated_latex_before_finetune)\n",
    "display(Math(generated_latex_before_finetune))\n",
    "\n",
    "similarity_before = calculate_latex_similarity(original_latex_test_case, generated_latex_before_finetune)\n",
    "print(f\"Similarity Score (Before Fine-tuning): {similarity_before:.4f}\")\n",
    "\n",
    "if generated_latex_before_finetune == original_latex_test_case:\n",
    "    print(\"Exact Match: YES (Unlikely before fine-tuning)\")\n",
    "else:\n",
    "    print(\"Exact Match: NO (Expected before fine-tuning)\")\n",
    "\n",
    "print(\"\\nOriginal Image:\")\n",
    "display(image_test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning with Unsloth and LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:17:43.348094Z",
     "iopub.status.busy": "2025-07-11T20:17:43.347588Z",
     "iopub.status.idle": "2025-07-11T20:31:42.912739Z",
     "shell.execute_reply": "2025-07-11T20:31:42.912143Z",
     "shell.execute_reply.started": "2025-07-11T20:17:43.348071Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Starting Fine-tuning Process with Unsloth and LoRA\n",
      "==================================================\n",
      "Unsloth: Making `base_model.model.model.vision_tower.vision_model` require gradients\n",
      "Unsloth: Switching to float32 training since model cannot work with float16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 68,686 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 38,497,792 of 4,338,577,264 (0.89% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 12:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.726500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.710200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.448500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.819900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.579400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.648900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.613700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.361000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.321300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.314900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.240900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.392300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.327300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.291200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.272700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.257900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.400700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.315400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning complete!\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Fine-tuning with Unsloth and LoRA ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"Starting Fine-tuning Process with Unsloth and LoRA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Add LoRA adapters to the model\n",
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = True,\n",
    "    finetune_language_layers   = True,\n",
    "    finetune_attention_modules = True,\n",
    "    finetune_mlp_modules       = True,\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    "    target_modules = \"all-linear\",\n",
    "    modules_to_save=[\n",
    "        \"lm_head\",\n",
    "        \"embed_tokens\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Enable model for training\n",
    "FastVisionModel.for_training(model)\n",
    "\n",
    "# Configure and setup the SFTTrainer\n",
    "from unsloth.trainer import UnslothVisionDataCollator # Import data collator\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=converted_train_dataset,\n",
    "    processing_class=processor.tokenizer,\n",
    "    data_collator=UnslothVisionDataCollator(model, processor),\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 1,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        gradient_checkpointing = True,\n",
    "        gradient_checkpointing_kwargs = {\"use_reentrant\": False},\n",
    "        max_grad_norm = 0.3,\n",
    "        warmup_ratio = 0.03,\n",
    "        max_steps = 30, # Keep steps low for demonstration, increase for full training\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        save_strategy=\"steps\",\n",
    "        optim = \"adamw_torch_fused\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"cosine\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"wandb\",\n",
    "        remove_unused_columns = False,\n",
    "        dataset_text_field = \"\",\n",
    "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
    "        dataset_num_proc = 2,\n",
    "        max_seq_length = 2048,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer_stats = trainer.train()\n",
    "print(\"\\nFine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See WandB metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:33:01.277544Z",
     "iopub.status.busy": "2025-07-11T20:33:01.276304Z",
     "iopub.status.idle": "2025-07-11T20:33:02.292571Z",
     "shell.execute_reply": "2025-07-11T20:33:02.291985Z",
     "shell.execute_reply.started": "2025-07-11T20:33:01.277515Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–„â–„â–…â–„â–…â–ˆâ–†â–„â–ƒâ–ƒâ–ˆâ–†â–ˆâ–†â–ƒâ–‚â–â–‚â–‚â–â–â–â–â–…â–â–‚â–‚â–‚â–â–‚</td></tr><tr><td>train/learning_rate</td><td>â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>train/loss</td><td>â–‡â–ˆâ–ˆâ–…â–„â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_flos</td><td>1963127618062464.0</td></tr><tr><td>train/epoch</td><td>0.00349</td></tr><tr><td>train/global_step</td><td>30</td></tr><tr><td>train/grad_norm</td><td>0.82985</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3154</td></tr><tr><td>train_loss</td><td>0.75549</td></tr><tr><td>train_runtime</td><td>826.0431</td></tr><tr><td>train_samples_per_second</td><td>0.291</td></tr><tr><td>train_steps_per_second</td><td>0.036</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">scarlet-blaze-13</strong> at: <a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset/runs/8oglq8p2?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset/runs/8oglq8p2?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9</a><br> View project at: <a href='https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9' target=\"_blank\">https://wandb.ai/zattuonline/Fine-tuning%20Gemma-3-4B%20on%20Latex-OCR%20Dataset?apiKey=be16707dadaf5ae00d126d832a9b27cd2215dfb9</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250711_192139-8oglq8p2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---. Finish WandB run ---\n",
    "if 'run' in locals() and run is not None:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model after Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:36:34.339324Z",
     "iopub.status.busy": "2025-07-11T20:36:34.338751Z",
     "iopub.status.idle": "2025-07-11T20:36:46.913640Z",
     "shell.execute_reply": "2025-07-11T20:36:46.913033Z",
     "shell.execute_reply.started": "2025-07-11T20:36:34.339297Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Testing Model Performance AFTER Fine-tuning\n",
      "==================================================\n",
      "\n",
      "--- Test Example (Index 12) AFTER Fine-tuning ---\n",
      "Original LaTeX:\n",
      "{ \\partial } ^ { \\mu } A _ { \\mu } ^ { a b } = A ^ { \\mu a c } B _ { \\mu } ^ { c b } - B ^ { \\mu a c } A _ { \\mu } ^ { c b } ,\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle { \\partial } ^ { \\mu } A _ { \\mu } ^ { a b } = A ^ { \\mu a c } B _ { \\mu } ^ { c b } - B ^ { \\mu a c } A _ { \\mu } ^ { c b } ,$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated LaTeX (After Fine-tuning):\n",
      "\\partial ^ { \\mu } A ^ { a b } _ { \\mu } = A ^ { \\mu c } A _ { \\mu } ^ { c b } - B _ { \\mu } ^ { c b } A _ { \\mu } ^ { c } ,\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\partial ^ { \\mu } A ^ { a b } _ { \\mu } = A ^ { \\mu c } A _ { \\mu } ^ { c b } - B _ { \\mu } ^ { c b } A _ { \\mu } ^ { c } ,$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score (After Fine-tuning): 0.5600\n",
      "Exact Match: NO (May still occur, but similarity should be higher)\n",
      "\n",
      "Original Image:\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=200x40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the model AFTER Fine-tuning \n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"Testing Model Performance AFTER Fine-tuning\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Set the fine-tuned model back to inference mode\n",
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "# Use the same test example as before to see the improvement\n",
    "print(f\"\\n--- Test Example (Index {test_example_index}) AFTER Fine-tuning ---\")\n",
    "generated_latex_after_finetune = generate_latex_from_image(model, processor, image_test_case, instruction)\n",
    "\n",
    "print(\"Original LaTeX:\")\n",
    "print(original_latex_test_case)\n",
    "display(Math(original_latex_test_case))\n",
    "\n",
    "print(\"Generated LaTeX (After Fine-tuning):\")\n",
    "print(generated_latex_after_finetune)\n",
    "display(Math(generated_latex_after_finetune))\n",
    "\n",
    "similarity_after = calculate_latex_similarity(original_latex_test_case, generated_latex_after_finetune)\n",
    "print(f\"Similarity Score (After Fine-tuning): {similarity_after:.4f}\")\n",
    "\n",
    "if generated_latex_after_finetune == original_latex_test_case:\n",
    "    print(\"Exact Match: YES (Expected after fine-tuning)\")\n",
    "else:\n",
    "    print(\"Exact Match: NO (May still occur, but similarity should be higher)\")\n",
    "\n",
    "print(\"\\nOriginal Image:\")\n",
    "display(image_test_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Fine-tuned Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:36:54.845842Z",
     "iopub.status.busy": "2025-07-11T20:36:54.845595Z",
     "iopub.status.idle": "2025-07-11T20:36:54.851752Z",
     "shell.execute_reply": "2025-07-11T20:36:54.850963Z",
     "shell.execute_reply.started": "2025-07-11T20:36:54.845824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- NEW Helper Function: Evaluate Model on Dataset ---\n",
    "def evaluate_model_on_dataset(model_to_eval, processor_to_eval, dataset_to_eval, instruction_text, num_examples=None):\n",
    "    \"\"\"\n",
    "    Evaluates the model's performance on a given dataset by calculating average similarity.\n",
    "    \"\"\"\n",
    "    print(f\"\\nEvaluating model on {len(dataset_to_eval) if num_examples is None else num_examples} examples...\")\n",
    "    total_similarity = 0\n",
    "    exact_matches = 0\n",
    "    examples_to_process = num_examples if num_examples is not None else len(dataset_to_eval)\n",
    "\n",
    "    for i in range(min(examples_to_process, len(dataset_to_eval))):\n",
    "        image = dataset_to_eval[i][\"image\"]\n",
    "        original_latex = dataset_to_eval[i][\"text\"]\n",
    "        generated_latex = generate_latex_from_image(model_to_eval, processor_to_eval, image, instruction_text)\n",
    "\n",
    "        similarity = calculate_latex_similarity(original_latex, generated_latex)\n",
    "        total_similarity += similarity\n",
    "\n",
    "        if original_latex == generated_latex:\n",
    "            exact_matches += 1\n",
    "\n",
    "        # Optional: print individual results for debugging\n",
    "        # print(f\"Example {i+1}: Original='{original_latex[:50]}...', Generated='{generated_latex[:50]}...', Sim={similarity:.4f}\")\n",
    "\n",
    "    avg_similarity = total_similarity / examples_to_process\n",
    "    exact_match_percentage = (exact_matches / examples_to_process) * 100\n",
    "\n",
    "    print(f\"\\n--- Evaluation Results (on {examples_to_process} examples) ---\")\n",
    "    print(f\"Average LaTeX Similarity: {avg_similarity:.4f}\")\n",
    "    print(f\"Exact Match Percentage: {exact_match_percentage:.2f}%\")\n",
    "    return avg_similarity, exact_match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:36:59.130846Z",
     "iopub.status.busy": "2025-07-11T20:36:59.130586Z",
     "iopub.status.idle": "2025-07-11T20:41:36.406359Z",
     "shell.execute_reply": "2025-07-11T20:41:36.405711Z",
     "shell.execute_reply.started": "2025-07-11T20:36:59.130828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Evaluating Fine-tuned Model on Test Dataset\n",
      "==================================================\n",
      "\n",
      "Evaluating model on 20 examples...\n",
      "\n",
      "--- Evaluation Results (on 20 examples) ---\n",
      "Average LaTeX Similarity: 0.5313\n",
      "Exact Match Percentage: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Fine-tuned Model on Test Dataset\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"Evaluating Fine-tuned Model on Test Dataset\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Set the fine-tuned model to inference mode (if not already)\n",
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "# Evaluate on a subset of the test dataset for quicker demonstration\n",
    "# For full evaluation, remove num_examples argument or set to len(test_dataset)\n",
    "avg_sim_test, exact_match_test = evaluate_model_on_dataset(model, processor, test_dataset, instruction, num_examples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the model to Huggingface Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a repo on Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:47:02.422297Z",
     "iopub.status.busy": "2025-07-11T20:47:02.421989Z",
     "iopub.status.idle": "2025-07-11T20:47:03.049311Z",
     "shell.execute_reply": "2025-07-11T20:47:03.048698Z",
     "shell.execute_reply.started": "2025-07-11T20:47:02.422276Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/zattuAI/gemma3-4b-latex-ocr-finetuned-merged', endpoint='https://huggingface.co', repo_type='model', repo_id='zattuAI/gemma3-4b-latex-ocr-finetuned-merged')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "\n",
    "# Only create the repo once \n",
    "# api.create_repo(\n",
    "#     repo_id=\"gemma3-4b-latex-ocr-finetuned-merged\",  # Will use your logged-in username\n",
    "#     repo_type=\"model\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:47:16.752576Z",
     "iopub.status.busy": "2025-07-11T20:47:16.752313Z",
     "iopub.status.idle": "2025-07-11T20:47:16.755961Z",
     "shell.execute_reply": "2025-07-11T20:47:16.755412Z",
     "shell.execute_reply.started": "2025-07-11T20:47:16.752556Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Set the HF_REPO_ID\n",
    "\n",
    "HF_REPO_ID = \"zattuAI/gemma3-4b-latex-ocr-finetuned-merged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T20:47:29.437751Z",
     "iopub.status.busy": "2025-07-11T20:47:29.437082Z",
     "iopub.status.idle": "2025-07-11T20:52:44.073171Z",
     "shell.execute_reply": "2025-07-11T20:52:44.072439Z",
     "shell.execute_reply.started": "2025-07-11T20:47:29.437725Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================\n",
      "Pushing fine-tuned MERGED model to Hugging Face Hub: zattuAI/gemma3-4b-latex-ocr-finetuned-merged\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d259d88da53a4203b829cf6ce98ff984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb271d97ff541e4a3f72c81cb481289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b00a96df554007b9e3fff0996ae9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: model-00001-of-00002.safetensors not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n",
      "Downloading safetensors index for unsloth/gemma-3-4b-pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a677d2dad8406f8c92a9628821c522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d552a9e80c4ff4a6183e7fca01db67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717f2d863a4b4e49b1143c1059681ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cf4634131c4565b4babd4d170d7cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [02:49<02:49, 169.63s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "820c21018ff94b17aafc8a52820917f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d45556dcca44f4bdcc0021a61c45a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [05:02<00:00, 151.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged model and processor successfully pushed to Hugging Face Hub!\n"
     ]
    }
   ],
   "source": [
    "# --- Push the fine-tuned model to Hugging Face Hub (Merged Float16) ---\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(f\"Pushing fine-tuned MERGED model to Hugging Face Hub: {HF_REPO_ID}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Save the merged model (base model + LoRA weights) in float16 precision\n",
    "    # This is ideal for deployment and general use by others.\n",
    "    model.push_to_hub_merged(HF_REPO_ID, processor, token=hf_token) # Pass the token explicitly\n",
    "    print(\"Merged model and processor successfully pushed to Hugging Face Hub!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error pushing merged model to Hugging Face Hub: {e}\")\n",
    "    print(\"Please ensure your HF_TOKEN environment variable is set correctly and has write access to the repository.\")\n",
    "    print(f\"Also, verify that the repository '{HF_REPO_ID}' exists or that you have permission to create it.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
